Common Intermediate Language (CIL)

How and when it's compiled into binary code by the JIT compiler.

Compiler turns .cs files into binary code, but there's more, two compilers.

When we build, the compiler (Named Roslyn), starts working, taking the .cs files and compiling them into CIL code which has a similar structure to java's bytecode. It's human readable, but not as much.

After we start it, the JIT compiler compiles the CIL into binary code and we can actually run that. It allows cross-platform compatibility so long as you have the .NET framework (which isn't C#, it's more akin to a framework, C# just so happens to be what we run on it most of the time.)

Not all files are compiled when we run as well since it's a JIT compiler.


Common Language Runtime (CLR)

It's a runtime environment that manages the execution of .NET apps.
Does the work we'd need to do on a lower level language like C, or ASM, like managing memory allocation.

The CLR manages all programs under .NET, so your F# or Iron Python apps as well.

A few of its responsibilities:

JIT Compilation;
Memory management (includes garbage collection);
Error handling;
Thread management.

Step by step, it goes like:

Step 1. We write code;
Step 2. Compiler compiles code into CIL;
Step 3. CLR kicks in, starts the program;
Step 4. CLR JIT compiles the CIL to binary;
Step 5. CLR manages the resources available to it & low level responsibilities.


MEMORY. Stack and heap.

We allocate memory no matter what we're doing, specifically, RAM.

Memory addresses, which are used on lower level languages by way of pointers... When we manipulate a variable in code, we're technically using the pointer, but in a different manner. In C, we can send an entire pointer as the parameter of a function, which in turn would allow us to make a function which technically returns no value but does manipulate the input which we sent to it, so much so that we could reset the address altogether and that memory address would forever become unavailable until we reset the machine.

Stack:

One per thread
Stacks are small, 1-4MB
No gaps between data
Automatical removal
Faster

Heap:

One per app
Heaps are larger
Can have chunks of empty data, defragmented
Cleaned up by the garbage collector
Slower

Example of value semantics & reference semantics in code on a project called "ReferenceVsValue"

TLDR of it, though:

Value is the value being held by it
Reference would be more akin to the place it is stored

While we can do
int num1 = 5;
int num2 = num1;
num2++;
And num2's value and hashcode will be different because they're different variables, if we make a custom object like
Person person1 = new Person();
Person person2 = person1;
If we run a person1.Equals(person2), the result will be true, and if we modify a variable in person2, or person1, they will both be modified. This is because we didn't create a new object for person2, we merely "told" it that it now holds the location of person1.



Value types:
Value semantics;
Derived from System.ValueType;
Simple build-in types, (int, decimal, DateTime, bool, etc.)
These are all structs.

Reference types:
Reference semantics;
Derived from System.Object;
Build-in classes and our classes are them.
List<T>, object, array.
All classes.

The real difference is that
var listA = new List<T>;
listA holds a reference to the location of it in memory, so much so that we can lose the values entirely if we do...

var listA = new List<T>;
var listB = new List<T>;
listA = listB;

The code above would make it impossible to ever get the values out of the list it used to refer to.

int a = 5; in the meantime, 'a' stores the value.

We make copies of values, like jotting down information on different pieces of paper. What we write on paper1 won't change paper2's values.

We don't make copies of references, we merely point towards them. Like asking where the paper in the previous example is located at.


As for what goes on in memory;

Value types are sent to the stack due to their simplicity.
Reference types on the other hand, the value of the reference is sent to the stack while the actual data is sent to the heap.
(The above explanation is simplified, aka, abstracted.)



Boxed types.
Universal types, boxed.

Value types are stored in the stack...
The references of a custom class, however, are on the stack. (the pointer)
The actual values, the object, are in the heap.

'object' types, though,
int number = 5;
Person person = new Person(value, value);
object boxedNumber = number;
boxedNumber is a 'reference' type variable, while its value is a 'value' type

The stack vs heap for that is
Stack
number (5), reference to person, reference to boxedNumber

Heap
Values of person (the object itself), object wrapping the number (object(5))

Boxing happens implicitly each time we assign a value type to an instance of reference type. (Most typically, System.Object.)

Interface types are also reference types, so
IComparable<int> intAsComparable = number;
Is a reference type wrapping a value type.

Boxing appears to be wrapping a value type in a reference type.
Unboxing is converting the boxed value back to the value type.
Unboxing must be done explicitly,
int unboxedNumber = (int)boxedNumber;

Boxing can be done implicitly because it'll always work, because everything can be assigned to a system.object type, but unboxing would fail if the value stored inside an object doesn't match the given type, so it must be done explicitly.

An error would be thrown if we did
short unboxedNumber = (short)boxedNumber;
instead of the example above, the error?
InvalidCastException.

Boxing: Wrapping a value type into an instance of System.Object, which is  areference type.
It's necessary to use all types in C# in a uniform way as objects.
Unboxing is the opposite, returning the boxed value to its original value type.
It does come with a performance penalty.

PERFORMANCE OF BOXING.

int a = 5; -> size of int: 4 bytes
object b = 5; -> size of int: 4 bytes, size of reference 4/8 bytes, total size? 8/12 bytes.
Create new object -> Allocate memory -> Cast on unboxing

Differences of boxing.
List<int> {1,2,3,4}
ArrayList {1,2,3,4}

List doesn't do boxing, it knows the type.
ArrayList does boxing for each element.

List<Icomparable<int>> {1,2,3,4} -> does boxing because interfaces are reference types.


List<int> numbers = new List<int> {1,2,3,4}
object asObject = numbers;

Naturally, you'd think boxing would happen, but, no.
Boxing happens when we wrap a value type in a reference type.
Here, we assign a List object to a variable of object type, but List is a reference type, so no boxing needs to happen. If "numbers" was, for example, an int, it would have to be boxed.




Garbage collector.

Everything in the code has a lifecycle, unusable objects that are no longer used need to be removed from memory so more resources can be allocated.
In .NET, the heap's memory management is the garbage collector.
Part of the common language runtime. 
Languages that are low level, like C or C++, we need to do it ourselves, but C# does it for us.

It doesn't immediately remove things from memory, so much so that you can activate debug mode, go into multiple lines on a functional program, and you'll still have access to the values a variable at the very top holds.

It's hard to tell when it'll do it, but we can force it to happen.

If we put "GC.Collect();" in our code, it'll make the garbage collector do its thing. It's rarely ever used.

The gc gets triggered when
1. When the OS informs the CLR that there's little memory left
2. When the amount of memory occupied by objects on the heap surpasses a given threshold
3. When we do it ourselves with GC.Collect
So... It works when it is needed.
The garbage collector works on its own thread, even on single thread apps.
It may stop other threads wehn working, and itll run in the background.
Might cause performance issues here and there, especially for things that need to run in real time.
Short lived objects that we create and destroy quickly that appear too much in, say, a game, would bloat up the heap and the GC would be running constantly. We can avoid creating loads of new objects to help this.



Memory fragmentation.

The garbage collector not only removes unused objects, but it also runs memory defragmentation.
As the GC remove objects from the memory, it creates gaps on it which can't really be filled, so defragmentation needs to happen in order for us to be able to use some addresses again.
It's like an array of bytes, and as we fill it up and use and then remove things from it, we can't simply slot certain things into it, so we move to the next available space, and once it's full, the GC does its thing, cleaning unused spaces and defragging memory




How does the GC decide what gets removed from memory.
Mark-And-Sweep algorithm.
Reference counting.
Circular reference.

Mark-And-Sweep.
First marks the objects that can be removed, then removes them.
It marks them by using reference counting, Gc keeps track of the count of references pointing to some objects, and when the count is zero, it counts it as unreferenced and marks that to be removed from memory.
There's problems about it, like objects that aren't used anywhere but hold references to each other. (This is circular reference.)

Since that is a possibility, .NET instead uses Tracing.
Determines if an object is reachable or not by tracing, tracing starts by identifying app roots.
If an object is reachable from any of the roots, it's included in the graph of the reachable objects, and if not reachable, is removed.
Circular references can't happen because they're not reachable.

What are application roots?
Static fields, local variables on the thread's stack. (Remember, each thread has its own stack.)

Summ.
To decide whether a refernece pointing to an object exists, the GC builds a graph of all objects reachable from root objects of the application.
Those that are unreachable are marked for exclusion.

Btw, its job is to manage the memory of the heap, not the stack.



Generations of objects, what are they and how they improve the performance of the GC.
What the large objects heap is, what it means when an object is pinned.

GC's responsibilites are to identify objects that are no longer used, removing objects from memory, AND defragging the memory.

So, imagine we've got a few objects, and the garbage collector does its thing.
The objects are still reachable, so the garbage collector does nothing.
The garbage collector will then run again, and again, and again, and if those same objects are still up and reachable, it likely means that they're long-lived, so, to save the trouble of checking those same objects every time, the GC instead opts to check those objects in particular only every now and again.

Generations of objects.
When objects are created, they're put in the zero generation.
If these objects survive through to the next cycle, they will eventually reach first or second generation.
The garbage collector will most frequently run checks and cleans on the zero generation, less frequently on first generation, and even less frequently on second generation.
It'll still check them, of course, but not as frequently as freshly made objects.

Think of a logging object created at the main class.
Its lifetime is as long as the app runs.
But something like a linq query, for example, will most likely not be used as often as a logging object.

In a well tuned app, most objects die at generation 0.
Also, during a collection of a generation, all previous generations are also collected.
So when generation 0 is collected, none other are, but when generation 2 is collected, generation 1 and 0 are collected.

LARGE OBJECT HEAPS (LOH)

When a large object is made, it's immediately assigned to generation 2, mostly because large objects are rarely ever short lived.
They're also pinned, which means they won't be moved in memory during defragmentation.

Summ.
GC divides objs into 3 generations, 0, 1, and 2.
As objects survive, they're moved to the next generations, which makes it easier for the GC to sweep things up.


MEMORY LEAKS!

Memory leaks. What they are, and how static fields can increase the risk of them.
A memory leak is when some memory addresses are not being cleaned, even when the objects occupying them aren't in use. You can see this in action on a C application by allocating space in RAM and then "losing" the pointer to that address. Memory addresses in C are allocated and unallocated by the developer, and since we can no longer know where those spaces are, it becomes impossible to remove things from those spaces. If you're running a loop that fills up your memory, you will eventually have your entire RAM allocated, and unless you restart your computer, you won't be able to use those addresses.

Anyhow, memory leaks happen when objects in memory that aren't used aren't being cleaned, and despite the use of a GC, it still doesn't fully protect us from memory leaks.

One of the most common sources of leaks in .NET are events (more about events later.)
But also, static fields, since they don't belong to an instance, but rather, a class.
I assume the reason is because we're not creating any objects that could eventually be cleaned, instead, merely "summoning" it ever so often. Static fields will never change either, so... They'll always be in memory.
Same for static variables, which can be in non-static classes.
(Static fields will be one of the roots for mark-and-sweep algorithm)
(Static variables are always reachable, and say, you have a static list holding all existing instances of the class you just made, well, those instances will all be stored in the list.)

The reason in particular as to why it creates memory leaks is that the instances within those classes will always be stored within a static variable, even if they're no longer in use. The GC won't clean those spaces because it cannot.
This is why we should in general avoid static classes.



DESTRUCTORS (Also known as finalizers.)

It is a special method executed on an object right before it is removed from memory by the GC.

To use destructors, it's the same as a constructor, but it looks like this:
~Destructor()
{
   Console.WriteLine("Destroyed.");
}

Example in a project called "Destructor"

We should never use destructors, but it is good to know that they exist, it's just generally a bad practice to use destructors, especially since due to the thread's behaviour, well, it'll delete resources at "random".
Funnily enough, there's times where the finalizer/destructor won't even be executed, it's super finnicky stuff, so you really shouldn't mess with it too much.

ALTHOUGH... If you are, for whatever reason, working with C# in unsafe memory mode, it could be useful, as the responsibility of allocating and deallocating resources is once again brought to the developer.
Pointers become available again., and you can even have unsafe functions.



Dispose method, managed and unmanaged resources.

Dispose comes from the IDisposable interface.

Managed resources are managed by the CLR, GC is aware of them, and it's the normal one, automatic cleanup.

Unmanaged resources aren't managed by the CLR, DB connections, file handles, opened network connections as well, GC isn't aware of them, and manual cleanup is necessary.

Classes that use unmanaged resources should implement the IDisposable interface.

Example in code inside a project called "FileWriter".

Dispose method is used to free and managed the resources. We need to implement it in classes that implement unmanaged resources.
We can use 'using' which is also exemplified in the "FileWriter" project.




Notes about the assignment...

Well, we changed the variable holding the row data. Before, we used a singular dictionary holding the value of 'object', thus, capable of handling all types of things. The drawback was that the boxing operation meant that simpler types like booleans, integers, and decimals, had to be boxed up into an object type, which considerably increased their memory consumption.
By instead having four dictionaries holding all possible types of data, we mitigate the boxing issue and store variables in their respective dictionaries.